# LLMPapers
包含当前自己能收集到的LLM的论文以及相关代码和演示demo路径。持续更新中。
# Instruct-Imagen: Image Generation with Multi-modal Instruction
谷歌最新发布的Instruct-Imagen：使用多模态指令生成图像
### 简介
这是一种处理异构图像生成任务并推广看不见的任务的模型。我们引入了用于图像生成的*多模态指令*，这是一种精确地表达一系列生成意图的任务表示。它使用自然语言来合并不同的模态（例如，文本、边缘、样式、主题等），以便可以以统一的格式标准化丰富的生成意图。然后，我们通过使用两阶段框架微调预训练的文本到图像扩散模型来构建 instruct-imagen。首先，我们使用检索增强训练来调整模型，以增强模型的能力，使其生成基于外部多模态上下文。随后，我们对需要视觉语言理解的各种图像生成任务（例如，主题驱动生成等）进行了调整模型的微调，每个任务都与封装任务本质的多模态指令配对。对各种图像生成数据集的人工评估表明，instruct-imagen 在域内匹配或超越了先前特定于任务的模型，并展示了对看不见和更复杂任务的有前途的泛化。
### 代码地址（暂未发布）

# LLaMA Pro: Progressive LLaMA with Block Expansion
腾讯发布LLaMA Pro：具有模块化扩展功能的渐进式 LLaMA
### 简介
人类通常会在不妥协旧技能的情况下获得新技能;然而，大型语言模型（LLM）则相反，例如，从LLaMA到CodeLLaMA。为此，我们提出了一种新的LLM后预训练方法，并扩展了Transformer模块。我们只使用新的语料库来调整扩展的块，有效地提高模型的知识，而不会发生灾难性的遗忘。在本文中，我们在代码和数学语料库上进行了实验，产生了LLaMA Pro-8.3B，这是一个从LLaMA2-7B初始化的通用基础模型，在一般任务、编程和数学方面表现出色。LLaMA Pro及其指令遵循对应物（LLaMA Pro-Instruct）在各种基准测试中实现了先进的性能，展示了优于LLaMA系列中现有的开放模型，以及作为智能代理推理和处理各种任务的巨大潜力。我们的研究结果为集成自然语言和编程语言提供了宝贵的见解，为开发在各种环境中有效运行的高级语言代理奠定了坚实的基础。
### 代码地址（未发布代码，静候中...)
https://github.com/TencentARC/LLaMA-Pro
